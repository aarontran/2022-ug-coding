{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWM9w37_BHOB"
   },
   "source": [
    "# 1. Brief Jupyter overview\n",
    "\n",
    "## 1.1 Installation, environments; get oriented\n",
    "\n",
    "__Question:__ What is the difference between `pip install`, `virtualenv`, and Conda (or Miniconda, Anaconda)?\n",
    "\n",
    "__Answer:__ They're different tools to manage Python package and software installation.  They determine where Python lives, and where packages like `numpy` and `astropy` are installed & then later \"searched for\", whenever you ask Python to import a library.\n",
    "\n",
    "Let's open a terminal to see where Python and its packages are installed, using the following bash commands.\n",
    "\n",
    "        which python\n",
    "        which ipython\n",
    "        which jupyter\n",
    "\n",
    "        ipython\n",
    "        >>> import numpy\n",
    "        >>> numpy.__file__\n",
    "        >>> numpy.__version__\n",
    "        >>> exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params= {\n",
    "    'figure.figsize': (10,8),\n",
    "    'axes.labelsize': 20,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.25,\n",
    "    'xtick.labelsize': 20,\n",
    "    'ytick.labelsize': 20,\n",
    "    'legend.fontsize': 15,\n",
    "    'xtick.minor.visible': True,\n",
    "    'ytick.minor.visible': True,\n",
    "    'xtick.major.size': 7,\n",
    "    'xtick.minor.size': 3,\n",
    "    'ytick.major.size': 7,\n",
    "    'ytick.minor.size': 3\n",
    "}\n",
    "\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiLerpthJem4"
   },
   "source": [
    "## 1.2 Using and navigating Jupyter\n",
    "\n",
    "* Code and text cells.\n",
    "* Command vs. insert mode: mouse click, `Esc`, `Return`\n",
    "* Execute cell: `Shift`+`Return`\n",
    "* Keyboard shortcuts in command mode: `a`, `b`, `x`, `c`, `v`, `dd`, `z`\n",
    "* Comment out code in bulk: `Cmd` (or `Ctrl`) + `/`\n",
    "* \"Restart kernel and run all cells\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpJWdzJLIUKm"
   },
   "outputs": [],
   "source": [
    "x = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVE6vv8pA5V6"
   },
   "outputs": [],
   "source": [
    "y = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJD1HESCPne-"
   },
   "outputs": [],
   "source": [
    "x + y  # during interactive Jupyter or IPython session, this is the same as print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPrIgX-NDtab"
   },
   "outputs": [],
   "source": [
    "y = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question:__ what happens if I delete all definitions of `x` and `y` above, then try to compute `x + y`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeKpqHo1CcM5"
   },
   "source": [
    "\n",
    "## 1.3 Useful tricks\n",
    "\n",
    "Markdown allows rich content: images, equations, HTML.  Example of a LaTeX equation that you can edit (double click this cell to see source code):\n",
    "\n",
    "$$\n",
    "  \\sum_{n=0}^{\\infty} \\frac{1}{x^n} = \\frac{1}{1-1/x}\n",
    "$$\n",
    "\n",
    "The IPython kernel within Jupyter has many useful tricks.  Let's look at a few:\n",
    "* `?` to get help, `??` to look at source.\n",
    "* `%history` (\"%\" commands are called \"line magics\")\n",
    "* `%%timeit` to benchmark your code (\"%%\" commands are called \"cell magics\")\n",
    "* `%load_ext autoreload`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history -l 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cpd9E6rzMdye"
   },
   "outputs": [],
   "source": [
    "range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeaozGupMkJp"
   },
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1CjU7WtNGXp"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x = 0\n",
    "for y in range(10000):\n",
    "    x += y\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x = sum(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXGmPEY1RJnM"
   },
   "outputs": [],
   "source": [
    "import my_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.foobar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.foobar??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2LWfsrrRLW2"
   },
   "outputs": [],
   "source": [
    "my_module.foobar(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uy6PcUHzQcbC"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUgzLNbrMVae",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.4 Other notes\n",
    "\n",
    "* How to run Jupyter notebook from a remote computer (e.g., if you have many GB or TB of data that won't fit on your computer): https://confluence.columbia.edu/confluence/display/rcs/Ginsburg+-+Job+Examples#GinsburgJobExamples-JupyterNotebooks\n",
    "\n",
    "## 1.5 References and Further Reading\n",
    "\n",
    "* IPython magic commands (`%` and `%%`): https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "\n",
    "* IPython autoreload: https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RWtVNG3DzxE"
   },
   "source": [
    "# 2. Getting the most out of NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGjVXg9nun8k"
   },
   "source": [
    "Python, in general, is slow; compared to compiled languages like C and Fortran, Python is woefully inefficient. But, this is where the magic of NumPy come into play: by wrapping C data structures and methods in Python commands, NumPy drastically speeds up array operations and numerical calculations. Learning to use NumPy properly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3NkNqi9uGFU"
   },
   "outputs": [],
   "source": [
    "# python lists vs. numpy arrays; memory comparison and append comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2od4uF1Pmazy"
   },
   "outputs": [],
   "source": [
    "# loop vs. array operations demo; examples of where we can get rid of loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vp4-oHyxuFSb"
   },
   "outputs": [],
   "source": [
    "# array slicing, np.where, and masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6m58IdNWEyC"
   },
   "outputs": [],
   "source": [
    "# np.vectorize and numpy functional programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Useful Scipy functions (curve_fit, fsolve, interpolate)\n",
    "## scipy.optimize.curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Planck's function\n",
    "def BB_lambdaT(l, T):\n",
    "  \n",
    "    #constants (SI units)\n",
    "    hplanck =6.62607015e-34 #m^2kg/s\n",
    "    clight =299792458. #m/s\n",
    "    kb =1.380649e-23 #m^2kg/(s^2K^1)\n",
    "\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make some data (blackbody + noise)\n",
    "\n",
    "factor=1.e12\n",
    "lambda_sun=np.linspace(100.e-9, 2000.e-9, 100) #wavelength range [m]\n",
    "T_sun=5778 # Sun's temp [K]\n",
    "BB_sun=BB_lambdaT(lambda_sun, T_sun)\n",
    "noise=factor*np.random.normal(size=len(lambda_sun)) #sample noise from a gaussian distribution\n",
    "BB_sun_data=BB_sun+noise\n",
    "\n",
    "#what happens to our fit when we increase noise (i.e. factor variable)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpack curve_fit outputs\n",
    "BB_params, BB_cov = curve_fit(f=BB_lambdaT, xdata=lambda_sun, ydata=BB_sun_data, p0=1000.)\n",
    "\n",
    "#if you have known errors on your data, you could also input them into curve_fit \n",
    "# via sigma and absolute_sigma parameters\n",
    "# other useful things to input are bounds on your parameters\n",
    "\n",
    "#fitted parameters (i.e. temperature)\n",
    "print(BB_params)\n",
    "\n",
    "#estimated covariance matrix\n",
    "print(BB_cov)\n",
    "\n",
    "#diagonal terms of the covariance matrix are our parameter variances\n",
    "#therefore, one-sigma errors on parameters are square root of the diagonal terms of the covariance matrix\n",
    "\n",
    "#1 sigma error in our temperature\n",
    "BB_params_stdev=np.sqrt(np.diag(BB_cov))\n",
    "print(BB_params_stdev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an array of the fitted values\n",
    "BB_sun_fit=BB_lambdaT(lambda_sun, BB_params[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just rounding up the parameters for the plot legend\n",
    "temp=int(np.round(BB_params[0],0))\n",
    "temp_sigma=int(np.round(BB_params_stdev[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's plot both our data & the fit\n",
    "plt.figure()\n",
    "plt.scatter(lambda_sun*1.e9, BB_sun_data/1.e12, marker='o',label='data', color='magenta')\n",
    "plt.plot(lambda_sun*1.e9, BB_sun_fit/1.e12, label=f'curve_fit: T$_\\odot$={temp}$\\pm${temp_sigma}', color='cyan')\n",
    "plt.legend()\n",
    "plt.xlabel('wavelength [nm]')\n",
    "plt.ylabel(r'intensity [kW/m$^{2}$/nm]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional notes:\n",
    "\n",
    "questions for discussion: When can curve_fit be useful? What are its limitations?\n",
    "\n",
    "resources: \n",
    "\n",
    "curve_fit uses non-linear least squares: \n",
    "https://en.wikipedia.org/wiki/Non-linear_least_squares\n",
    "\n",
    "some resources to learn/review about the covariance matrix:\n",
    "https://mathworld.wolfram.com/Covariance.html\n",
    "https://towardsdatascience.com/understanding-the-covariance-matrix-92076554ea44\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy.interpolate.interpolate1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some sparse data\n",
    "#let's use power law since it's common to encounter in astronomy :)\n",
    "x_values=np.array([0,4,11,40,75,100], dtype=np.float64)\n",
    "powerlaw_curve=x_values**0.3\n",
    "\n",
    "#now let's create interpolator functions using different methods \n",
    "nearest = interp1d(x_values, powerlaw_curve, kind='nearest') #nearest neighbor\n",
    "linear = interp1d(x_values, powerlaw_curve, kind='linear') #linear spline\n",
    "cubic = interp1d(x_values, powerlaw_curve, kind='cubic') #cubic spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets take some well-sampled x-array\n",
    "x_values_interp=np.linspace(1,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and interpolate for those values\n",
    "powerlaw_curve_nearest=nearest(x_values_interp)\n",
    "powerlaw_curve_linear=linear(x_values_interp)\n",
    "powerlaw_curve_cubic=cubic(x_values_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot our sparse data\n",
    "plt.figure()\n",
    "plt.scatter(x_values, powerlaw_curve, marker='d',label='data',s=50)\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel(r'x$^{0.3}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot our interpolated data for three methods\n",
    "plt.figure()\n",
    "plt.scatter(x_values, powerlaw_curve, marker='d',label='data')\n",
    "plt.scatter(x_values_interp, powerlaw_curve_nearest, marker='x',label='nearest')\n",
    "plt.scatter(x_values_interp, powerlaw_curve_linear, marker='*',label='linear')\n",
    "plt.scatter(x_values_interp, powerlaw_curve_cubic, marker='o',label='cubic')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel(r'x$^{0.3}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional notes:\n",
    "questions for discussion: how do you choose your interpolator? when are interpolators useful?\n",
    "\n",
    "other helpful functions: scipy.interpolate.interp2d, scipy.interpolate.griddata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy.optimize.fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "#define a function that you want to find the roots of\n",
    "def func(x):\n",
    "    \n",
    "    return (x-10.11)*(x+1.15)*(x-4.6)*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot it\n",
    "xs=np.linspace(-20,20,100)\n",
    "plt.plot(xs, func(xs))\n",
    "plt.hlines(0,-20,20, ls='--')\n",
    "# plt.ylim([-500,1000])\n",
    "# plt.xlim([-5,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve for roots with initial guesses\n",
    "roots=fsolve(func, x0=[-2,0,3,9])\n",
    "roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve for roots with bad initial guesses\n",
    "roots=fsolve(func, x0=[-20,30,5,1000])\n",
    "roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve for roots but decrease running time\n",
    "roots=fsolve(func, x0=[-2,0,3,9],maxfev=10)\n",
    "roots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional notes:\n",
    "questions for discussion: when can fsolve be useful?\n",
    "other useful functions: root "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing and reading files with Astropy and NumPy\n",
    "## Astropy tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some particle data: their IDs and 3-D position coordinates\n",
    "\n",
    "pID=np.array([1, 2, 3, 4, 5])\n",
    "x=np.array([2., 4., 6., 8., 10.])\n",
    "y=np.array([1., 4., 9., 16., 25.])\n",
    "z=np.array([1., 1., 1., 1., 1.])\n",
    "\n",
    "particle_info='particle positions \\n particle ID, x, y, z' #define file comment string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's create and write a table to a file \n",
    "particle_table=Table([pID, x, y, z], names=['pID','x', 'y','z'])\n",
    "particle_table.write('particles.csv', format='ascii.csv', overwrite=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "particle_read=Table.read('particles.csv', format='ascii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for large files, setting guess=False when reading a file can noticeably decrease computational time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy.savetxt and numpy.loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save arrays and comment at the top of the file\n",
    "np.savetxt('particles.txt', (pID, x, y, z), fmt='%1.1f', header=particle_info)\n",
    "particles_read_txt=np.loadtxt('particles.txt', dtype=np.float64)\n",
    "print(particles_read_txt)\n",
    "print(particles_read_txt[0,:])\n",
    "\n",
    "#arrays are saved as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's stack our arrays as columns instead\n",
    "np.savetxt('particles.txt', np.column_stack([pID, x, y, z]), fmt=\"%1.1f\", header=particle_info)\n",
    "particles_read_txt=np.loadtxt('particles.txt', dtype=np.float64)\n",
    "print(particles_read_txt)\n",
    "print(particles_read_txt[:,0])\n",
    "#now arrays are saved as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also unpack the txt file into separate arrays\n",
    "IDs, x_pos, y_pos, z_pos=np.loadtxt('particles.txt', dtype=np.float64, unpack=True)\n",
    "print(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets add more particles\n",
    "add_ID=np.arange(6,10,1)\n",
    "add_x=add_y=add_z=np.arange(1,5,1)\n",
    "print(add_ID)\n",
    "print(add_x)\n",
    "np.savetxt('particles.txt', np.column_stack([add_ID, add_x, add_y, add_z]), fmt=\"%1.1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the file\n",
    "IDs, x_pos, y_pos, z_pos=np.loadtxt('particles.txt', dtype=np.float64, unpack=True)\n",
    "print(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets append to the file instead \n",
    "with open('particles.txt','a') as particle_file:\n",
    "    np.savetxt(particle_file, np.column_stack([add_ID, add_x, add_y, add_z]), fmt=\"%1.1f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's check again\n",
    "IDs, x_pos, y_pos, z_pos=np.loadtxt('particles.txt', dtype=np.float64, unpack=True)\n",
    "print(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what happens if we explicitly open the file\n",
    "particle_file=open('particles.txt','w')\n",
    "np.savetxt(particle_file, np.column_stack([add_ID, add_x, add_y, add_z]), fmt=\"%1.1f\")\n",
    "#particle_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional notes:\n",
    "see also numpy.genfromtxt -- useful when some data is missing\n",
    "see also functions in the pandas package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uh6uORTqXAaX"
   },
   "source": [
    "# 4. Check your work with units and constants in AstroPy\n",
    "\n",
    "What is inside astropy's `units` submodule?  Quoting the [documentation](https://docs.astropy.org/en/stable/units/index.html),\n",
    "\n",
    "> `astropy.units` handles defining, converting between, and performing arithmetic with physical quantities, such as meters, seconds, Hz, etc. It also handles logarithmic units such as magnitude and decibel.\n",
    "> \n",
    "> `astropy.units` does not know spherical geometry or sexagesimal (hours, min, sec): if you want to deal with celestial coordinates, see the `astropy.coordinates` package.\n",
    "\n",
    "We'll explore how to use astropy `units`, and how it can help us guard against bugs and mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Overview of astropy.units\n",
    "\n",
    "Just a glimpse, not comprehensive -- there's more in the documentation and various online tutorials.\n",
    "\n",
    "### Start by playing around with some built-in units, to see what's possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDpeYU8oMAaZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "\n",
    "from astropy import units as u\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "qDXdmJU5NtO3",
    "outputId": "ecd8f49e-d78f-4a1d-ec45-a9f6e1f0cf3d"
   },
   "outputs": [],
   "source": [
    "u.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "53pZ7YeSNvpt",
    "outputId": "5656fe71-d30d-4cd1-d390-b366fd727843"
   },
   "outputs": [],
   "source": [
    "u.meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "G_0qFQk1NyNP",
    "outputId": "858a4a4c-fbc7-412e-d06c-26b1fec45809"
   },
   "outputs": [],
   "source": [
    "u.picometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AflA3I4N0kW",
    "outputId": "d1eb39b8-7cfb-48c6-d556-4ddf3c669a73"
   },
   "outputs": [],
   "source": [
    "u.picometer.to(u.m)  # ask audience: give me a unit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8BIhEJWODdT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u.picometer.to(u.g)  # ask audience: give me another unit! (make sure to do both length & \"not-length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force = 5 * u.m * u.kg / u.s**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(force.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force.unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force.cgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force.si"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Doing math with units\n",
    "\n",
    "Let's return to the Planck blackbody function as a motivating example.\n",
    "\n",
    "$$\n",
    "    B_{\\lambda}(\\lambda, T)\n",
    "    = \\frac{2 h c^2}{\\lambda^5}\n",
    "    \\frac{1}{\\exp\\left(\\frac{hc}{\\lambda k_B T} -1\\right)}\n",
    "$$\n",
    "\n",
    "with Planck's constant $h$, speed of light $c$, and Boltzmann constant $k_B$.\n",
    "\n",
    "Planck's function, expressed in per-wavelength form ($B_\\lambda$ rather than $B_\\nu$), has units of radiance per wavelength.  That is power per steradian per area per wavelength.  Phew!\n",
    "\n",
    "### How would we program this function with units?  How does having units help us?\n",
    "\n",
    "Note: we need to attach the \"per-steradian\" piece manually.  Angular units like radians and steradians are dimensionless, and steradians don't already show up in the constants $h$, $c$, $k_B$, nor in our inputs $\\lambda$, $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_lambdaT(l, T):\n",
    "    #constants (SI units)\n",
    "    hplanck=6.62607015e-34 #m^2kg/s\n",
    "    clight=299792458. #m/s\n",
    "    kb=1.380649e-23 #m^2kg/(s^2K^1)\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import constants as const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const.k_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_lambdaT(l, T):\n",
    "    hplanck = const.h\n",
    "    clight = const.c\n",
    "    kb = const.k_B\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.) / u.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, if we forget to put in units, we get a `UnitConversionError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BB_lambdaT(400e-9, 5778)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With units, it seems to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(400*u.nm, 5778*u.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try converting it to the expected form, power per solid angle per area per wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(400*u.nm, 5778*u.K).to(u.Watt/u.sr/u.m**2/u.m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we accidentally swap the order of our inputs?\n",
    "\n",
    "Units will give an extra hint that something is amiss.  You may not have memorized the typical magnitude of the Sun's spectral radiance, but you might more easily recognize that $\\mathrm{Kelvin}^5$ looks fishy in the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(5778*u.K, 400*u.nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The units submodule works seamlessly with numpy and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sun = np.linspace(100e-9, 2000e-9, 100) * u.m #wavelength range [m]\n",
    "T_sun = 5778 * u.K # sun's temp [K]\n",
    "sun_BB = BB_lambdaT(lambda_sun, T_sun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_sun, sun_BB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The units submodule has a nice auto-labeling feature with matplotlib, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astropy.visualization.quantity_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_sun, sun_BB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_sun.to(u.nm), sun_BB)\n",
    "plt.axvspan(4000*u.Angstrom, 7000*u.Angstrom, facecolor='g', alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have a nice, clean working function, let's add a \"docstring\" to finish the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_lambdaT(l, T):\n",
    "    \"\"\"\n",
    "    Planck's blackbody function per unit wavelength\n",
    "    Reference: Zombeck, Handbook of Space Astronomy and Astrophysics, 2nd Ed., page 268.\n",
    "    \n",
    "    Arguments:\n",
    "        l: wavelength in astropy units (length), scalar or array\n",
    "        T: temperature in astropy units (Kelvin), scalar or array\n",
    "    Returns:\n",
    "        value(s) of Planck's function evaluated at (l, T) with astropy units attached\n",
    "    \"\"\"\n",
    "    hplanck = const.h\n",
    "    clight = const.c\n",
    "    kb = const.k_B\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.) / u.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Extra: a little more \"defensive programming\"\n",
    "\n",
    "We've seen that astropy units can help us write correct, concise, and more readable code, and we've seen that the units submodule works cleanly with `numpy` and `matplotlib`.\n",
    "\n",
    "__Exercise:__ what if we give correct units, but unphysical values to the blackbody function?  Try modifying the function `BB_lambdaT(...)` to prevent the user from inputting negative values.  You might use: `assert`, `raise Exception`, `np.any(...)`, `np.all(...)`.\n",
    "\n",
    "As you modify the function, make sure it works on previous input (both scalar and array).  This is called \"regression testing\", to check that new changes to your function don't cause it to regress in other unexpected ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(-100*u.m, -1000*u.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add assertion checks for `l` and `T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_lambdaT(l, T):\n",
    "    \"\"\"\n",
    "    Planck's blackbody function per unit wavelength\n",
    "    Reference: Zombeck, Handbook of Space Astronomy and Astrophysics, 2nd Ed., page 268.\n",
    "    \n",
    "    Arguments:\n",
    "        l: wavelength in astropy units (length), scalar or array. Must be >= 0.\n",
    "        T: temperature in astropy units (Kelvin), scalar or array. Must be >= 0.\n",
    "    Returns:\n",
    "        value(s) of Planck's function evaluated at (l, T) with astropy units attached\n",
    "    \"\"\"\n",
    "    assert l >= 0\n",
    "    assert T >= 0\n",
    "    hplanck = const.h\n",
    "    clight = const.c\n",
    "    kb = const.k_B\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.) / u.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function throws an error for negative scalar inputs, as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(-100*u.m, -1000*u.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the function works on previous input by trying to re-generate the plot we made above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sun = np.linspace(100e-9, 2000e-9, 100) * u.m #wavelength range [m]\n",
    "T_sun = 5778 * u.K # sun's temp [K]\n",
    "sun_BB = BB_lambdaT(lambda_sun, T_sun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woops, we did break something!  Let's fix it.\n",
    "\n",
    "The code `l >= 0` returns a numpy array of Booleans.  As the error message says, the truth value of an array with more than one message is ambiguous: should we treat `[True, False, False, True, True]` as `True` or `False`??  Let's guard against _any_ negative input values for wavelength or temperature by using `np.any(...)`, similar to what is suggested.\n",
    "\n",
    "Instead of `np.any(l >= 0)`, notice that we could also write `(l >= 0).any()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_lambdaT(l, T):\n",
    "    \"\"\"\n",
    "    Planck's blackbody function per unit wavelength\n",
    "    Reference: Zombeck, Handbook of Space Astronomy and Astrophysics, 2nd Ed., page 268.\n",
    "    \n",
    "    Arguments:\n",
    "        l: wavelength in astropy units (length), scalar or array. Must be >= 0.\n",
    "        T: temperature in astropy units (Kelvin), scalar or array. Must be >= 0.\n",
    "    Returns:\n",
    "        value(s) of Planck's function evaluated at (l, T) with astropy units attached\n",
    "    \"\"\"\n",
    "    assert np.any(l >= 0)\n",
    "    assert np.any(T >= 0)\n",
    "    hplanck = const.h\n",
    "    clight = const.c\n",
    "    kb = const.k_B\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.) / u.sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sun = np.linspace(100e-9, 2000e-9, 100) * u.m #wavelength range [m]\n",
    "T_sun = 5778 * u.K # sun's temp [K]\n",
    "sun_BB = BB_lambdaT(lambda_sun, T_sun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_sun.to(u.nm), sun_BB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our function passes the \"regression test\".  Let's re-confirm that it gives the correct error for either negative scalar or array input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sun = np.linspace(100e-9, 2000e-9, 100) * u.m #wavelength range [m]\n",
    "T_sun = -1 * 5778 * u.K # sun's temp [K]\n",
    "sun_BB = BB_lambdaT(lambda_sun, T_sun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(-100*u.m, -1000*u.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Some general remarks\n",
    "\n",
    "Defensive programming is not a cure-all!  Bugs can come in other ways.  It's also possible to be too careful and to clutter your code needlessly.  Some personal taste / practice is involved.\n",
    "\n",
    "Why should we use astropy units specifically?  What other tools can help us perform calculations with units?\n",
    "* Wolfram|Alpha, for quick one-off calculations with units: https://www.wolframalpha.com/\n",
    "* `yt` and `unyt` provide unit-aware interfaces for simulation outputs: https://yt-project.org/\n",
    "* Many other specialized packages will provide their own unit packages.  Different packages / systems may not talk easily with one another (but, can be aided by projects like `yt`).  Example from a well-used simulation code: https://arepo-code.org/wp-content/userguide/parameterfile.html#system-of-units\n",
    "\n",
    "\n",
    "## 4.5 References\n",
    "\n",
    "* Documentation: https://docs.astropy.org/en/stable/units/index.html\n",
    "* Tutorials on astropy units specifically:\n",
    "  + (recommended) https://learn.astropy.org/tutorials/quantities.html\n",
    "  + https://astropy4cambridge.readthedocs.io/en/latest/_static/Astropy%20-%20Unit%20Conversion.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Parting thoughts on scientific computing, generally\n",
    "\n",
    "\n",
    "* Programming in Python, and working with command-line software in general, are skills learned by lots of trial and error, Googling for answers, and __asking friends and mentors__.  More senior mentors may not be as up-to-date on current software trends and development: peers, graduate students, postdocs can be good resources.  Such skills can also be learned in CS classes, which can be especially helpful if you are interested in more computational aspects of astro.  They will go farther than what is strictly needed for most day-to-day astro work.\n",
    "\n",
    "\n",
    "* Many community organizations run one- or multi-day workshops for scientific computing skills, and may have some curricula online.\n",
    "  + [Software Carpentry](https://software-carpentry.org/)\n",
    "  + [Flatiron Sciware](http://sciware.flatironinstitute.org/)\n",
    "  + [Code/Astro](https://semaphorep.github.io/codeastro/), recently run at the AAS Summer Meeting\n",
    "\n",
    "\n",
    "* You often don't have to re-invent the wheel!  Many, many libraries and built-in functions exist.\n",
    "\n",
    "\n",
    "* Visualization is a deep subject on its own.  One starting point: think about accessibility for colorblind viewers.\n",
    "\n",
    "\n",
    "* Mathematica notebooks are another powerful tool, especially for symbolic math.  Downsides: proprietary/closed source, cost.  You can get a free license at https://www.cuit.columbia.edu/content/mathematica.  Mathematica appeared in 1988, before Python's first release in 1991(!), and helped pave the way towards IPython notebooks / Jupyter.\n",
    "\n",
    "\n",
    "* Coding style: https://google.github.io/styleguide/pyguide.html. Much is not applicable for scientists, and much is a matter of taste (unlike big teams working on shared code, where people need to agree on a consistent style).  But you may find some useful nuggets.  For example,\n",
    "  + good practices for docstrings and comments\n",
    "  + a suggestion to keep functions <= 40 lines (a suggestion that I routinely break myself!..)\n",
    "  + 2.19 \"Avoid power features\"\n",
    "  + 3.16 \"Naming\"\n",
    "\n",
    "\n",
    "* Some suggested best practices in scientific computing: https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Undergrad Research Coding Workshop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
