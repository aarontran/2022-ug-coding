{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWM9w37_BHOB"
   },
   "source": [
    "# 1. Brief Jupyter overview\n",
    "\n",
    "## 1.1 Installation, environments; get oriented\n",
    "\n",
    "__Question:__ What is the difference between `pip install`, `virtualenv`, and Conda (or Miniconda, Anaconda)?\n",
    "\n",
    "__Answer:__ They're different tools to manage Python package and software installation.  They determine where Python lives, and where packages like `numpy` and `astropy` are installed & then later \"searched for\", whenever you ask Python to import a library.\n",
    "\n",
    "Let's open a terminal to see where Python and its packages are installed, using the following bash commands.\n",
    "\n",
    "        which python\n",
    "        which ipython\n",
    "        which jupyter\n",
    "\n",
    "        ipython\n",
    "        >>> import numpy\n",
    "        >>> numpy.__file__\n",
    "        >>> numpy.__version__\n",
    "        >>> exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params= {\n",
    "    'figure.figsize': (10,8),\n",
    "    'axes.labelsize': 20,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.25,\n",
    "    'xtick.labelsize': 20,\n",
    "    'ytick.labelsize': 20,\n",
    "    'legend.fontsize': 15,\n",
    "    'xtick.minor.visible': True,\n",
    "    'ytick.minor.visible': True,\n",
    "    'xtick.major.size': 7,\n",
    "    'xtick.minor.size': 3,\n",
    "    'ytick.major.size': 7,\n",
    "    'ytick.minor.size': 3\n",
    "}\n",
    "\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiLerpthJem4"
   },
   "source": [
    "## 1.2 Using and navigating Jupyter\n",
    "\n",
    "* Code and text cells.\n",
    "* Command vs. insert mode: mouse click, `Esc`, `Return`\n",
    "* Execute cell: `Shift`+`Return`\n",
    "* Keyboard shortcuts in command mode: `a`, `b`, `x`, `c`, `v`, `dd`, `z`\n",
    "* Comment out code in bulk: `Cmd` (or `Ctrl`) + `/`\n",
    "* \"Restart kernel and run all cells\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpJWdzJLIUKm"
   },
   "outputs": [],
   "source": [
    "x = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVE6vv8pA5V6"
   },
   "outputs": [],
   "source": [
    "y = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJD1HESCPne-"
   },
   "outputs": [],
   "source": [
    "x + y  # during interactive Jupyter or IPython session, this is the same as print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPrIgX-NDtab"
   },
   "outputs": [],
   "source": [
    "y = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question:__ what happens if I delete all definitions of `x` and `y` above, then try to compute `x + y`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeKpqHo1CcM5"
   },
   "source": [
    "\n",
    "## 1.3 Useful tricks\n",
    "\n",
    "Markdown allows rich content: images, equations, HTML.  Example of a LaTeX equation that you can edit (double click this cell to see source code):\n",
    "\n",
    "$$\n",
    "  \\sum_{n=0}^{\\infty} \\frac{1}{x^n} = \\frac{1}{1-1/x}\n",
    "$$\n",
    "\n",
    "The IPython kernel within Jupyter has many useful tricks.  Let's look at a few:\n",
    "* `?` to get help, `??` to look at source.\n",
    "* `%history` (\"%\" commands are called \"line magics\")\n",
    "* `%%timeit` to benchmark your code (\"%%\" commands are called \"cell magics\")\n",
    "* `%load_ext autoreload`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history -l 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cpd9E6rzMdye"
   },
   "outputs": [],
   "source": [
    "range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeaozGupMkJp"
   },
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1CjU7WtNGXp"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x = 0\n",
    "for y in range(10000):\n",
    "    x += y\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x = sum(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXGmPEY1RJnM"
   },
   "outputs": [],
   "source": [
    "import my_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.foobar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.foobar??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2LWfsrrRLW2"
   },
   "outputs": [],
   "source": [
    "my_module.foobar(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uy6PcUHzQcbC"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUgzLNbrMVae",
    "tags": []
   },
   "source": [
    "## 1.4 Other notes\n",
    "\n",
    "* How to run Jupyter notebook from a remote computer (e.g., if you have many GB or TB of data that won't fit on your computer): https://confluence.columbia.edu/confluence/display/rcs/Ginsburg+-+Job+Examples#GinsburgJobExamples-JupyterNotebooks\n",
    "\n",
    "## 1.5 References and Further Reading\n",
    "\n",
    "* IPython magic commands (`%` and `%%`): https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "\n",
    "* IPython autoreload: https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Getting the most out of NumPy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python, in general, is slow; compared to compiled languages like C and Fortran, Python is woefully inefficient. But, this is where the magic of NumPy come into play: by wrapping C data structures and methods in Python commands, NumPy drastically speeds up array operations and numerical calculations. Learning to use NumPy properly can do wonders for your Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python lists vs. NumPy arrays: when to use which?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending to python lists is faster than appending to NumPy arrays!\n",
    "\n",
    "l1 = []\n",
    "a1 = np.array([])\n",
    "\n",
    "# append 1000 elements to a list\n",
    "t1 = time.time()\n",
    "for i in range(1000):\n",
    "    l1.append(i)\n",
    "t2 = time.time()\n",
    "\n",
    "# append 1000 elements to a NumPy array\n",
    "t3 = time.time()\n",
    "for i in range(1000):\n",
    "    a1 = np.append(a1, np.array(i))\n",
    "t4 = time.time()\n",
    "\n",
    "print(f\"List time: {t2-t1}; NumPy array time: {t4-t3}\")  # more than an order of magnitude difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thankfully, python lists and NumPy arrays can be interconverted (in most cases)\n",
    "\n",
    "converted_array = a1.tolist()\n",
    "converted_list = np.array(l1)\n",
    "print(f\"Converted array size: {len(converted_array)}; Converted list size: {np.size(converted_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list \"arithmetic\" can quickly build long lists (while NumPy array arithmetic just applies a function to an array)\n",
    "\n",
    "# some tricks for adding elements to python lists\n",
    "\n",
    "l2 = [1, 3, 4, 5]\n",
    "\n",
    "l2_more = l2 + [6, 7, 8]  # concatenate two lists with +\n",
    "l2_triple = l2 * 3     # copy a list 3 times using *\n",
    "l2.insert(1, 2)      # insert an element into index 1 of the list\n",
    "print(l2_more, l2_triple, l2)\n",
    "\n",
    "string_list = ['cat', 'dog', 'mouse']    # the above operations also work with other data types, like strings!\n",
    "string_list_double = string_list * 2\n",
    "string_list += ['cat'] * 4   # append 'cat' to the original string_list 4 times\n",
    "print(string_list_double, string_list)\n",
    "\n",
    "\n",
    "# try the same stuff with a NumPy array\n",
    "\n",
    "a2 = np.array([1,3,4,5])\n",
    "a2 = a2 * 2    # multiplies each element by 2\n",
    "print(a2)\n",
    "\n",
    "string_array = np.array(['cat', 'dog', 'mouse'])\n",
    "string_array = string_array * 2    # raises an error; strings generally shouldn't be used in NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python lists can hold multiple different data types (including other lists), while NumPy arrays are meant to be *homogeneous*\n",
    "\n",
    "l3 = [4, \"cat\", \"dog\", [\"meow\"]]\n",
    "print(l3[0], l3[3])\n",
    "l3 = l3 * 2\n",
    "print(l3)\n",
    "\n",
    "bad_array1 = np.array(l3)    # throws a warning about creating an array with a nested list\n",
    "bad_array2 = np.array([4, \"cat\", \"dog\"])\n",
    "bad_array2 = bad_array2 * 2  # throws an error because array isn't homogeneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy array operations are *much* faster than loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: summing elements in an array\n",
    "\n",
    "sum_array = np.arange(10000)  # create the array [0, 1, 2, 3, ..., 9999] (could also use linspace)\n",
    "\n",
    "t1 = time.time()\n",
    "sum1 = np.sum(sum_array)   # sum all elements in sum_array using a NumPy array operation\n",
    "t2 = time.time()\n",
    "\n",
    "sum2 = 0\n",
    "t3 =  time.time()\n",
    "for i in range(sum_array.size):\n",
    "    sum2 += sum_array[i]    # sum all elements in sum_array using a for-loop \n",
    "t4 = time.time()\n",
    "\n",
    "print(sum1, sum2)\n",
    "print(f\"NumPy operation time: {t2-t1}; Loop time: {t4-t3}\")    # an order of magnitude difference in time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example: listing an integer's factors\n",
    "\n",
    "n = 1345986\n",
    "possible_factors = np.arange(1, n+1)  # create the array [1, 2, 3, ..., n]\n",
    "\n",
    "# try using NumPy arrays\n",
    "t1 = time.time()\n",
    "remainders = n % possible_factors  # modulo (%) acts on the entire possible_factors array\n",
    "# print(remainders)\n",
    "factors_np = possible_factors[np.where(remainders == 0)]  # pick out the elements of possible_factors that coincide with 0s in the remainders array\n",
    "t2 = time.time()\n",
    "print(factors_np)\n",
    "print(\"\\n\")\n",
    "\n",
    "# try using a for-loop over a python list\n",
    "factors_list = []\n",
    "t3 = time.time()\n",
    "for p in possible_factors:\n",
    "    if (n % p == 0): factors_list.append(p)\n",
    "t4 = time.time()\n",
    "print(factors_list)\n",
    "\n",
    "print(f\"\\n NumPy operation time: {t2-t1}; Loop time: {t4-t3}\")  # huge time difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rid of for-loops can take some finesse... some strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1: always check for built-in NumPy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful functions (by no means an exhaustive list)\n",
    "\n",
    "test_array = np.array([0, 0, 1, 5, 8, np.nan, 14])\n",
    "\n",
    "where_nonzeros = np.nonzero(test_array)  # check which array entries are non-zero\n",
    "print(where_nonzeros)\n",
    "\n",
    "where_nans = np.isnan(test_array)  # check which array entries are NaN (i.e., not a number, likely resulting from division by 0)\n",
    "print(where_nans)\n",
    "\n",
    "array_max = np.max(test_array)        # find the maximum element of test_array\n",
    "array_nanmax = np.nanmax(test_array)  # find the maximum element of test_array, ignoring NaNs\n",
    "where_max = np.nanargmax(test_array)  # find the index of the maximum element of test_array, ignoring NaNs\n",
    "print(array_max, array_nanmax, where_max)\n",
    "\n",
    "# + lots of linear algebra stuff: https://numpy.org/doc/stable/reference/routines.linalg.html\n",
    "# + lots of array manipulation functions: https://numpy.org/doc/stable/reference/routines.array-manipulation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2: use slicing and masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some masking examples\n",
    "\n",
    "a3 = np.array([0, 1, 3, 5, 8, 0, 10])\n",
    "\n",
    "mask = a3 > 5            # array of booleans, True if an element of a3 is greater than 5, false otherwise\n",
    "masked_a3 = a3[mask]                  # apply mask to a3 to pick out only the elements that are greater than 5\n",
    "print(masked_a3)\n",
    "\n",
    "nozeros_a3 = a3[np.nonzero(a3)]    # many built-in numpy functions create specialized masks\n",
    "print(nozeros_a3)\n",
    "\n",
    "\n",
    "# np.where provides an alternative means of masking and manipulating arrays\n",
    "\n",
    "masked_a3_alt = a3[np.where(a3 > 5)]       # create a mask with np.where and apply it immediately\n",
    "altered_a3 = np.where(a3 > 5, 3*a3, a3/3)  # if an element in a3 is greater than 5, replace it with thrice that element; otherwise divide the element by 3\n",
    "print(masked_a3_alt, altered_a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some more masking examples\n",
    "\n",
    "another_array = np.array([10, 9, 15, 37, 5, 9, 3])\n",
    "\n",
    "cross_masked = a3[np.where(another_array % 5 == 0)]   # build and apply a mask from another array\n",
    "print(cross_masked)\n",
    "\n",
    "scrambled_array = another_array[[6, 4, 5, 0, 1, 3, 2]]   # can also use indices as a mask\n",
    "print(scrambled_array)\n",
    "\n",
    "sort_indices = np.argsort(another_array)    # get the indices that would put another_array in sorted order\n",
    "sorted_array = another_array[sort_indices]  # sort another_array using sort_indices\n",
    "print(sort_indices, sorted_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some slicing examples\n",
    "\n",
    "full_array = np.array([1, 1, 4, 5, 9, 10])\n",
    "\n",
    "no_first = full_array[1:]     # cut off the first element of full_array\n",
    "no_last = full_array[:-1]     # cut off the last element\n",
    "every_other = full_array[::2] # view every other element\n",
    "start_stop_step = full_array[1:5:2]  # start at index 1, stop at index 5 (exclusive), and step in intervals of 2\n",
    "print(no_first, no_last, every_other, start_stop_step)\n",
    "\n",
    "full_array[1:5:2] = full_array[1:5:2] * 2   # can use slices to modify array elements in-place\n",
    "print(full_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 3: don't be afraid to use higher-dimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: generate a Binomial distribution via Monte-Carlo simulation\n",
    "\n",
    "p = 0.5  # probability of success\n",
    "n = 100  # number of trials per experiment/simulation\n",
    "jmax = 1000  # number of simulations to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# Kipping's code\n",
    "\n",
    "# Define lists we will need using comprehension\n",
    "trial = [i+1 for i in range(n)]  # define an integer list\n",
    "frac = [0 for i in range(n)]     # define an empty list\n",
    "\n",
    "for j in range(jmax): # big loop for each simulation\n",
    "    k = 0   # counter for the number of successes achieved\n",
    "    \n",
    "    for i in range(n):\n",
    "        uniform = np.random.uniform()\n",
    "        if uniform < p:         # if uniform < p, then we have a success\n",
    "            k = k+1             # increase counter to reflect success\n",
    "        frac[i] = float(k)/float(trial[i])\n",
    "        \n",
    "    # append results to an array using vertical stack\n",
    "    if j > 0:\n",
    "        results_kipping = np.vstack([results_kipping,frac])\n",
    "    else:\n",
    "        results_kipping = np.array(frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# my code\n",
    "\n",
    "rand_probs = np.random.uniform(size=(jmax, n))\n",
    "trial_nums = np.arange(1, n+1)\n",
    "results_me = np.cumsum(rand_probs > p, axis=1) / trial_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you feed pyplot a 2D array, it'll plot each of the columns separately; .T (transpose) flips rows and columns\n",
    "\n",
    "plt.plot(np.tile(trial_nums, (jmax,1)).T, results_me.T, color=\"black\", alpha=0.1)\n",
    "plt.xlabel(\"number of flips\")\n",
    "plt.ylabel(\"fraction of heads\")\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,100)\n",
    "\n",
    "# fraction of heads approaches normal distribution as number of flips grows\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 1: turn our previous routine for finding factors into a function\n",
    "\n",
    "def count_factors(n):\n",
    "    \n",
    "    if (n <= 0): return 0\n",
    "    \n",
    "    remainders = n % possible_factors  \n",
    "    factors_np = possible_factors[np.where(remainders == 0)]\n",
    "    \n",
    "    return factors_np.size\n",
    "\n",
    "\n",
    "# vectorize our function to make it compatible with array inputs\n",
    "\n",
    "count_factors_vec = np.vectorize(count_factors)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.arange(1000)    # generate a list of numbers\n",
    "\n",
    "# use the vectorized function to apply count_factors to every element in ns\n",
    "t1 = time.time()\n",
    "count_factors_vec(ns)   \n",
    "t2 = time.time()\n",
    "\n",
    "# use a loop to apply count_factors to every element in ns\n",
    "count_factors_list = []\n",
    "t3 = time.time()\n",
    "for n in ns:\n",
    "    count_factors_list.append(count_factors(n))  \n",
    "t4 = time.time()\n",
    "\n",
    "print(f\"Vectorized time: {t2-t1}; Loop time: {t4-t3}\")  # not a very big time difference; vectorize is mostly for convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy API reference: https://numpy.org/doc/stable/reference/index.html\n",
    "\n",
    "Using multidimensional array: http://www.math.buffalo.edu/~badzioch/MTH337/PT/PT-multidimensional_numpy_arrays/PT-multidimensional_numpy_arrays.html\n",
    "\n",
    "Broadcasting: https://www.tutorialspoint.com/numpy/numpy_broadcasting.htm, \n",
    "https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "\n",
    "NumPy array manipulation routines: https://numpy.org/doc/stable/reference/routines.array-manipulation.html\n",
    "\n",
    "Linear algebra in NumPy: https://numpy.org/doc/stable/reference/routines.linalg.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Useful Scipy functions (curve_fit, fsolve, interpolate)\n",
    "## scipy.optimize.curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Planck's function\n",
    "def BB_lambdaT(l, T):\n",
    "  \n",
    "    #constants (SI units)\n",
    "    hplanck =6.62607015e-34 #m^2kg/s\n",
    "    clight =299792458. #m/s\n",
    "    kb =1.380649e-23 #m^2kg/(s^2K^1)\n",
    "\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make some data (blackbody + noise)\n",
    "\n",
    "factor=1.e12\n",
    "lambda_sun=np.linspace(100.e-9, 2000.e-9, 100) #wavelength range [m]\n",
    "T_sun=5778 # Sun's temp [K]\n",
    "BB_sun=BB_lambdaT(lambda_sun, T_sun)\n",
    "noise=factor*np.random.normal(size=len(lambda_sun)) #sample noise from a gaussian distribution\n",
    "BB_sun_data=BB_sun+noise\n",
    "\n",
    "#what happens to our fit when we increase noise (i.e. factor variable)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpack curve_fit outputs\n",
    "BB_params, BB_cov = curve_fit(f=BB_lambdaT, xdata=lambda_sun, ydata=BB_sun_data, p0=1000.)\n",
    "\n",
    "#if you have known errors on your data, you could also input them into curve_fit \n",
    "# via sigma and absolute_sigma parameters\n",
    "# other useful things to input are bounds on your parameters\n",
    "\n",
    "#fitted parameters (i.e. temperature)\n",
    "print(BB_params)\n",
    "\n",
    "#estimated covariance matrix\n",
    "print(BB_cov)\n",
    "\n",
    "#diagonal terms of the covariance matrix are our parameter variances\n",
    "#therefore, one-sigma errors on parameters are square root of the diagonal terms of the covariance matrix\n",
    "\n",
    "#1 sigma error in our temperature\n",
    "BB_params_stdev=np.sqrt(np.diag(BB_cov))\n",
    "print(BB_params_stdev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an array of the fitted values\n",
    "BB_sun_fit=BB_lambdaT(lambda_sun, BB_params[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just rounding up the parameters for the plot legend\n",
    "temp=int(np.round(BB_params[0],0))\n",
    "temp_sigma=int(np.round(BB_params_stdev[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's plot both our data & the fit\n",
    "plt.figure()\n",
    "plt.scatter(lambda_sun*1.e9, BB_sun_data/1.e12, marker='o',label='data', color='magenta')\n",
    "plt.plot(lambda_sun*1.e9, BB_sun_fit/1.e12, label=f'curve_fit: T$_\\odot$={temp}$\\pm${temp_sigma}', color='cyan')\n",
    "plt.legend()\n",
    "plt.xlabel('wavelength [nm]')\n",
    "plt.ylabel(r'intensity [kW/m$^{2}$/nm]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional notes:\n",
    "\n",
    "questions for discussion: When can curve_fit be useful? What are its limitations?\n",
    "\n",
    "resources: \n",
    "\n",
    "curve_fit uses non-linear least squares: \n",
    "https://en.wikipedia.org/wiki/Non-linear_least_squares\n",
    "\n",
    "some resources to learn/review about the covariance matrix:\n",
    "https://mathworld.wolfram.com/Covariance.html\n",
    "https://towardsdatascience.com/understanding-the-covariance-matrix-92076554ea44\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy.interpolate.interpolate1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some sparse data\n",
    "#let's use power law since it's common to encounter in astronomy :)\n",
    "x_values=np.array([0,4,11,40,75,100], dtype=np.float64)\n",
    "powerlaw_curve=x_values**0.3\n",
    "\n",
    "#now let's create interpolator functions using different methods \n",
    "nearest = interp1d(x_values, powerlaw_curve, kind='nearest') #nearest neighbor\n",
    "linear = interp1d(x_values, powerlaw_curve, kind='linear') #linear spline\n",
    "cubic = interp1d(x_values, powerlaw_curve, kind='cubic') #cubic spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets take some well-sampled x-array\n",
    "x_values_interp=np.linspace(1,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and interpolate for those values\n",
    "powerlaw_curve_nearest=nearest(x_values_interp)\n",
    "powerlaw_curve_linear=linear(x_values_interp)\n",
    "powerlaw_curve_cubic=cubic(x_values_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot our sparse data\n",
    "plt.figure()\n",
    "plt.scatter(x_values, powerlaw_curve, marker='d',label='data',s=50)\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel(r'x$^{0.3}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot our interpolated data for three methods\n",
    "plt.figure()\n",
    "plt.scatter(x_values, powerlaw_curve, marker='d',label='data')\n",
    "plt.scatter(x_values_interp, powerlaw_curve_nearest, marker='x',label='nearest')\n",
    "plt.scatter(x_values_interp, powerlaw_curve_linear, marker='*',label='linear')\n",
    "plt.scatter(x_values_interp, powerlaw_curve_cubic, marker='o',label='cubic')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel(r'x$^{0.3}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional notes:\n",
    "questions for discussion: how do you choose your interpolator? when are interpolators useful?\n",
    "\n",
    "other helpful functions: scipy.interpolate.interp2d, scipy.interpolate.griddata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy.optimize.fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "#define a function that you want to find the roots of\n",
    "def func(x):\n",
    "    \n",
    "    return (x-10.11)*(x+1.15)*(x-4.6)*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot it\n",
    "xs=np.linspace(-20,20,100)\n",
    "plt.plot(xs, func(xs))\n",
    "plt.hlines(0,-20,20, ls='--')\n",
    "# plt.ylim([-500,1000])\n",
    "# plt.xlim([-5,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve for roots with initial guesses\n",
    "roots=fsolve(func, x0=[-2,0,3,9])\n",
    "roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve for roots with bad initial guesses\n",
    "roots=fsolve(func, x0=[-20,30,5,1000])\n",
    "roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve for roots but decrease running time\n",
    "roots=fsolve(func, x0=[-2,0,3,9],maxfev=10)\n",
    "roots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional notes:\n",
    "questions for discussion: when can fsolve be useful?\n",
    "other useful functions: root "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing and reading files with Astropy and NumPy\n",
    "## Astropy tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some particle data: their IDs and 3-D position coordinates\n",
    "\n",
    "pID=np.array([1, 2, 3, 4, 5])\n",
    "x=np.array([2., 4., 6., 8., 10.])\n",
    "y=np.array([1., 4., 9., 16., 25.])\n",
    "z=np.array([1., 1., 1., 1., 1.])\n",
    "\n",
    "particle_info='particle positions \\n particle ID, x, y, z' #define file comment string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's create and write a table to a file \n",
    "particle_table=Table([pID, x, y, z], names=['pID','x', 'y','z'])\n",
    "particle_table.write('particles.csv', format='ascii.csv', overwrite=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "particle_read=Table.read('particles.csv', format='ascii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for large files, setting guess=False when reading a file can noticeably decrease computational time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy.savetxt and numpy.loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save arrays and comment at the top of the file\n",
    "np.savetxt('particles.txt', (pID, x, y, z), fmt='%1.1f', header=particle_info)\n",
    "particles_read_txt=np.loadtxt('particles.txt', dtype=np.float64)\n",
    "print(particles_read_txt)\n",
    "print(particles_read_txt[0,:])\n",
    "\n",
    "#arrays are saved as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's stack our arrays as columns instead\n",
    "np.savetxt('particles.txt', np.column_stack([pID, x, y, z]), fmt=\"%1.1f\", header=particle_info)\n",
    "particles_read_txt=np.loadtxt('particles.txt', dtype=np.float64)\n",
    "print(particles_read_txt)\n",
    "print(particles_read_txt[:,0])\n",
    "#now arrays are saved as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also unpack the txt file into separate arrays\n",
    "IDs, x_pos, y_pos, z_pos=np.loadtxt('particles.txt', dtype=np.float64, unpack=True)\n",
    "print(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets add more particles\n",
    "add_ID=np.arange(6,10,1)\n",
    "add_x=add_y=add_z=np.arange(1,5,1)\n",
    "print(add_ID)\n",
    "print(add_x)\n",
    "np.savetxt('particles.txt', np.column_stack([add_ID, add_x, add_y, add_z]), fmt=\"%1.1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the file\n",
    "IDs, x_pos, y_pos, z_pos=np.loadtxt('particles.txt', dtype=np.float64, unpack=True)\n",
    "print(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets append to the file instead \n",
    "with open('particles.txt','a') as particle_file:\n",
    "    np.savetxt(particle_file, np.column_stack([add_ID, add_x, add_y, add_z]), fmt=\"%1.1f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's check again\n",
    "IDs, x_pos, y_pos, z_pos=np.loadtxt('particles.txt', dtype=np.float64, unpack=True)\n",
    "print(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what happens if we explicitly open the file\n",
    "particle_file=open('particles.txt','w')\n",
    "np.savetxt(particle_file, np.column_stack([add_ID, add_x, add_y, add_z]), fmt=\"%1.1f\")\n",
    "#particle_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional notes:\n",
    "see also numpy.genfromtxt -- useful when some data is missing\n",
    "see also functions in the pandas package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uh6uORTqXAaX"
   },
   "source": [
    "# 4. Check your work with units and constants in AstroPy\n",
    "\n",
    "What is inside astropy's `units` submodule?  Quoting the [documentation](https://docs.astropy.org/en/stable/units/index.html),\n",
    "\n",
    "> `astropy.units` handles defining, converting between, and performing arithmetic with physical quantities, such as meters, seconds, Hz, etc. It also handles logarithmic units such as magnitude and decibel.\n",
    "> \n",
    "> `astropy.units` does not know spherical geometry or sexagesimal (hours, min, sec): if you want to deal with celestial coordinates, see the `astropy.coordinates` package.\n",
    "\n",
    "We'll explore how to use astropy `units`, and how it can help us guard against bugs and mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Overview of astropy.units\n",
    "\n",
    "Just a glimpse, not comprehensive -- there's more in the documentation and various online tutorials.\n",
    "\n",
    "### Start by playing around with some built-in units, to see what's possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDpeYU8oMAaZ"
   },
   "outputs": [],
   "source": [
    "from astropy import units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "qDXdmJU5NtO3",
    "outputId": "ecd8f49e-d78f-4a1d-ec45-a9f6e1f0cf3d"
   },
   "outputs": [],
   "source": [
    "u.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "53pZ7YeSNvpt",
    "outputId": "5656fe71-d30d-4cd1-d390-b366fd727843"
   },
   "outputs": [],
   "source": [
    "u.meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "G_0qFQk1NyNP",
    "outputId": "858a4a4c-fbc7-412e-d06c-26b1fec45809"
   },
   "outputs": [],
   "source": [
    "u.picometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AflA3I4N0kW",
    "outputId": "d1eb39b8-7cfb-48c6-d556-4ddf3c669a73"
   },
   "outputs": [],
   "source": [
    "u.picometer.to(u.m)  # ask audience: give me a unit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8BIhEJWODdT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u.picometer.to(u.g)  # ask audience: give me another unit! (make sure to do both length & \"not-length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force = 5 * u.m * u.kg / u.s**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(force.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force.unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force.cgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force.si"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Doing math with units\n",
    "\n",
    "Let's return to the Planck blackbody function as a motivating example.\n",
    "\n",
    "$$\n",
    "    B_{\\lambda}(\\lambda, T)\n",
    "    = \\frac{2 h c^2}{\\lambda^5}\n",
    "    \\frac{1}{\\exp\\left(\\frac{hc}{\\lambda k_B T} -1\\right)}\n",
    "$$\n",
    "\n",
    "with Planck's constant $h$, speed of light $c$, and Boltzmann constant $k_B$.\n",
    "\n",
    "Planck's function, expressed in per-wavelength form ($B_\\lambda$ rather than $B_\\nu$), has units of radiance per wavelength.  That is power per steradian per area per wavelength.  Phew!\n",
    "\n",
    "### How would we program this function with units?  How does having units help us?\n",
    "\n",
    "Note: we need to attach the \"per-steradian\" piece manually.  Angular units like radians and steradians are dimensionless, and steradians don't already show up in the constants $h$, $c$, $k_B$, nor in our inputs $\\lambda$, $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_lambdaT(l, T):\n",
    "    #constants (SI units)\n",
    "    hplanck=6.62607015e-34 #m^2kg/s\n",
    "    clight=299792458. #m/s\n",
    "    kb=1.380649e-23 #m^2kg/(s^2K^1)\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import constants as const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const.k_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_lambdaT(l, T):\n",
    "    hplanck = const.h\n",
    "    clight = const.c\n",
    "    kb = const.k_B\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.) / u.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, if we forget to put in units, we get a `UnitConversionError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BB_lambdaT(400e-9, 5778)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With units, it seems to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(400*u.nm, 5778*u.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try converting it to the expected form, power per solid angle per area per wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(400*u.nm, 5778*u.K).to(u.Watt/u.sr/u.m**2/u.m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we accidentally swap the order of our inputs?\n",
    "\n",
    "Units will give an extra hint that something is amiss.  You may not have memorized the typical magnitude of the Sun's spectral radiance, but you might more easily recognize that $\\mathrm{Kelvin}^5$ looks fishy in the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(5778*u.K, 400*u.nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The units submodule works seamlessly with numpy and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sun = np.linspace(100e-9, 2000e-9, 100) * u.m #wavelength range [m]\n",
    "T_sun = 5778 * u.K # sun's temp [K]\n",
    "sun_BB = BB_lambdaT(lambda_sun, T_sun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_sun, sun_BB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The units submodule has a nice auto-labeling feature with matplotlib, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astropy.visualization.quantity_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_sun, sun_BB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_sun.to(u.nm), sun_BB)\n",
    "plt.axvspan(4000*u.Angstrom, 7000*u.Angstrom, facecolor='g', alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have a nice, clean working function, let's add a \"docstring\" to finish the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_lambdaT(l, T):\n",
    "    \"\"\"\n",
    "    Planck's blackbody function per unit wavelength\n",
    "    Reference: Zombeck, Handbook of Space Astronomy and Astrophysics, 2nd Ed., page 268.\n",
    "    \n",
    "    Arguments:\n",
    "        l: wavelength in astropy units (length), scalar or array\n",
    "        T: temperature in astropy units (Kelvin), scalar or array\n",
    "    Returns:\n",
    "        value(s) of Planck's function evaluated at (l, T) with astropy units attached\n",
    "    \"\"\"\n",
    "    hplanck = const.h\n",
    "    clight = const.c\n",
    "    kb = const.k_B\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.) / u.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Extra: a little more \"defensive programming\"\n",
    "\n",
    "We've seen that astropy units can help us write correct, concise, and more readable code, and we've seen that the units submodule works cleanly with `numpy` and `matplotlib`.\n",
    "\n",
    "__Exercise:__ what if we give correct units, but unphysical values to the blackbody function?  Try modifying the function `BB_lambdaT(...)` to prevent the user from inputting negative values.  You might use: `assert`, `raise Exception`, `np.any(...)`, `np.all(...)`.\n",
    "\n",
    "As you modify the function, make sure it works on previous input (both scalar and array).  This is called \"regression testing\", to check that new changes to your function don't cause it to regress in other unexpected ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(-100*u.m, -1000*u.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add assertion checks for `l` and `T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_lambdaT(l, T):\n",
    "    \"\"\"\n",
    "    Planck's blackbody function per unit wavelength\n",
    "    Reference: Zombeck, Handbook of Space Astronomy and Astrophysics, 2nd Ed., page 268.\n",
    "    \n",
    "    Arguments:\n",
    "        l: wavelength in astropy units (length), scalar or array. Must be >= 0.\n",
    "        T: temperature in astropy units (Kelvin), scalar or array. Must be >= 0.\n",
    "    Returns:\n",
    "        value(s) of Planck's function evaluated at (l, T) with astropy units attached\n",
    "    \"\"\"\n",
    "    assert l >= 0\n",
    "    assert T >= 0\n",
    "    hplanck = const.h\n",
    "    clight = const.c\n",
    "    kb = const.k_B\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.) / u.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function throws an error for negative scalar inputs, as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(-100*u.m, -1000*u.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the function works on previous input by trying to re-generate the plot we made above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sun = np.linspace(100e-9, 2000e-9, 100) * u.m #wavelength range [m]\n",
    "T_sun = 5778 * u.K # sun's temp [K]\n",
    "sun_BB = BB_lambdaT(lambda_sun, T_sun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woops, we did break something!  Let's fix it.\n",
    "\n",
    "The code `l >= 0` returns a numpy array of Booleans.  As the error message says, the truth value of an array with more than one message is ambiguous: should we treat `[True, False, False, True, True]` as `True` or `False`??  Let's guard against _any_ negative input values for wavelength or temperature by using `np.any(...)`, similar to what is suggested.\n",
    "\n",
    "Instead of `np.any(l >= 0)`, notice that we could also write `(l >= 0).any()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB_lambdaT(l, T):\n",
    "    \"\"\"\n",
    "    Planck's blackbody function per unit wavelength\n",
    "    Reference: Zombeck, Handbook of Space Astronomy and Astrophysics, 2nd Ed., page 268.\n",
    "    \n",
    "    Arguments:\n",
    "        l: wavelength in astropy units (length), scalar or array. Must be >= 0.\n",
    "        T: temperature in astropy units (Kelvin), scalar or array. Must be >= 0.\n",
    "    Returns:\n",
    "        value(s) of Planck's function evaluated at (l, T) with astropy units attached\n",
    "    \"\"\"\n",
    "    assert np.any(l >= 0)\n",
    "    assert np.any(T >= 0)\n",
    "    hplanck = const.h\n",
    "    clight = const.c\n",
    "    kb = const.k_B\n",
    "    return (2.*hplanck*clight**2/l**5)/(np.exp(hplanck*clight/(l*kb*T))-1.) / u.sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sun = np.linspace(100e-9, 2000e-9, 100) * u.m #wavelength range [m]\n",
    "T_sun = 5778 * u.K # sun's temp [K]\n",
    "sun_BB = BB_lambdaT(lambda_sun, T_sun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_sun.to(u.nm), sun_BB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our function passes the \"regression test\".  Let's re-confirm that it gives the correct error for either negative scalar or array input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sun = np.linspace(100e-9, 2000e-9, 100) * u.m #wavelength range [m]\n",
    "T_sun = -1 * 5778 * u.K # sun's temp [K]\n",
    "sun_BB = BB_lambdaT(lambda_sun, T_sun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB_lambdaT(-100*u.m, -1000*u.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Some general remarks\n",
    "\n",
    "Defensive programming is not a cure-all!  Bugs can come in other ways.  It's also possible to be too careful and to clutter your code needlessly.  Some personal taste / practice is involved.\n",
    "\n",
    "Why should we use astropy units specifically?  What other tools can help us perform calculations with units?\n",
    "* Wolfram|Alpha, for quick one-off calculations with units: https://www.wolframalpha.com/\n",
    "* `yt` and `unyt` provide unit-aware interfaces for simulation outputs: https://yt-project.org/\n",
    "* Many other specialized packages will provide their own unit packages.  Different packages / systems may not talk easily with one another (but, can be aided by projects like `yt`).  Example from a well-used simulation code: https://arepo-code.org/wp-content/userguide/parameterfile.html#system-of-units\n",
    "\n",
    "\n",
    "## 4.5 References\n",
    "\n",
    "* Documentation: https://docs.astropy.org/en/stable/units/index.html\n",
    "* Tutorials on astropy units specifically:\n",
    "  + (recommended) https://learn.astropy.org/tutorials/quantities.html\n",
    "  + https://astropy4cambridge.readthedocs.io/en/latest/_static/Astropy%20-%20Unit%20Conversion.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Parting thoughts on scientific computing, generally\n",
    "\n",
    "\n",
    "* Programming in Python, and working with command-line software in general, are skills learned by lots of trial and error, Googling for answers, and __asking friends and mentors__.  More senior mentors may not be as up-to-date on current software trends and development: peers, graduate students, postdocs can be good resources.  Such skills can also be learned in CS classes, which can be especially helpful if you are interested in more computational aspects of astro.  They will go farther than what is strictly needed for most day-to-day astro work.\n",
    "\n",
    "\n",
    "* Many community organizations run one- or multi-day workshops for scientific computing skills, and may have some curricula online.\n",
    "  + [Software Carpentry](https://software-carpentry.org/)\n",
    "  + [Flatiron Sciware](http://sciware.flatironinstitute.org/)\n",
    "  + [Code/Astro](https://semaphorep.github.io/codeastro/), recently run at the AAS Summer Meeting\n",
    "\n",
    "\n",
    "* You often don't have to re-invent the wheel!  Many, many libraries and built-in functions exist.\n",
    "\n",
    "\n",
    "* Visualization is a deep subject on its own.  One starting point: think about accessibility for colorblind viewers.\n",
    "\n",
    "\n",
    "* Mathematica notebooks are another powerful tool, especially for symbolic math.  Downsides: proprietary/closed source, cost.  You can get a free license at https://www.cuit.columbia.edu/content/mathematica.  Mathematica appeared in 1988, before Python's first release in 1991(!), and helped pave the way towards IPython notebooks / Jupyter.\n",
    "\n",
    "\n",
    "* Coding style: https://google.github.io/styleguide/pyguide.html. Much is not applicable for scientists, and much is a matter of taste (unlike big teams working on shared code, where people need to agree on a consistent style).  But you may find some useful nuggets.  For example,\n",
    "  + good practices for docstrings and comments\n",
    "  + a suggestion to keep functions <= 40 lines (a suggestion that I routinely break myself!..)\n",
    "  + 2.19 \"Avoid power features\"\n",
    "  + 3.16 \"Naming\"\n",
    "\n",
    "\n",
    "* Some suggested best practices in scientific computing: https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Undergrad Research Coding Workshop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
